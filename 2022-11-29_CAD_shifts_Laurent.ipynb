{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e6ede3a-e8c0-4753-8bde-c5ac49d2d276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python3 -m pip install --user neo elephant viziphant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e607479",
   "metadata": {},
   "source": [
    "#  Cell assembly detection (CAD)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c0163f5-b685-412d-b5c6-8ff1670e9998",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import quantities as pq\n",
    "import neo\n",
    "import elephant\n",
    "import viziphant\n",
    "from elephant.conversion import BinnedSpikeTrain\n",
    "np.random.seed(4542)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5488bfdb",
   "metadata": {},
   "source": [
    "## introducing heterogeneous delays\n",
    "\n",
    "the function developed in the scan + a shift in time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "717a2fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_sync = 0.05\n",
    "shift = 0.01\n",
    "A = [0]+[1.-A_sync]+[0]*8+[A_sync]\n",
    "spiketrains = elephant.spike_train_generation.compound_poisson_process(\n",
    "                             rate=5*pq.Hz, A=A, shift=shift*pq.s, t_stop=10*pq.s)\n",
    "bst = BinnedSpikeTrain(spiketrains, bin_size=1 * pq.ms)                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37a20b77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BinnedSpikeTrain(t_start=0.0 s, t_stop=10.0 s, bin_size=0.001 s; shape=(10, 10000), format=csr_matrix)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2e6a0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "bst.rescale('ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37a20b77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BinnedSpikeTrain(t_start=0.0 ms, t_stop=10000.0 ms, bin_size=1.0 ms; shape=(10, 10000), format=csr_matrix)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd9b1d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m\n",
      "\u001b[0mcell_assembly_detection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mbinned_spiketrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmax_lag\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mreference_lag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmin_occurrences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0msize_chunks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmax_spikes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0msignificance_pruning\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0msubgroup_pruning\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0msame_configuration_pruning\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mbool_times_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "Perform the CAD analysis :cite:`cad-Russo2017_e19428` for the binned\n",
      "(discretized) spike trains given in the input. The method looks for\n",
      "candidate significant patterns with lags (number of bins between successive\n",
      "spikes in the pattern) ranging from `-max_lag` to `max_lag` (the second\n",
      "parameter of the function). Thus, between two successive spikes in the\n",
      "pattern there can be at most `max_lag`*`bin_size` units of time.\n",
      "\n",
      "The method agglomerates pairs of units (or a unit and a preexisting\n",
      "assembly), tests their significance by a statistical test\n",
      "and stops when the detected assemblies reach their maximal dimension\n",
      "(parameter `max_spikes`).\n",
      "\n",
      "At every agglomeration size step (e.g. from triplets to quadruplets), the\n",
      "method filters patterns having the same neurons involved, and keeps only\n",
      "the most significant one. This pruning is optional and the choice is\n",
      "identified by the parameter 'significance_pruning'.\n",
      "Assemblies already included in a bigger assembly are eliminated in a final\n",
      "pruning step. Also this pruning is optional, and the choice is identified\n",
      "by the parameter `subgroup_pruning`.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "binned_spiketrain : elephant.conversion.BinnedSpikeTrain\n",
      "    Binned spike trains containing data to be analyzed.\n",
      "max_lag : int\n",
      "    Maximal lag to be tested. For a binning dimension of bin_size the\n",
      "    method will test all pairs configurations with a time\n",
      "    shift between '-max_lag' and 'max_lag'.\n",
      "reference_lag : int, optional\n",
      "    Reference lag (in bins) for the non-stationarity correction in the\n",
      "    statistical test.\n",
      "    Default: 2\n",
      "alpha : float, optional\n",
      "    Significance level for the statistical test.\n",
      "    Default: 0.05\n",
      "min_occurrences : int, optional\n",
      "    Minimal number of occurrences required for an assembly\n",
      "    (all assemblies, even if significant, with fewer occurrences\n",
      "    than min_occurrences are discarded).\n",
      "    Default: 0\n",
      "size_chunks : int, optional\n",
      "    Size (in bins) of chunks in which the spike trains are divided\n",
      "    to compute the variance (to reduce non stationarity effects\n",
      "    on variance estimation).\n",
      "    Default: 100\n",
      "max_spikes : int, optional\n",
      "    Maximal assembly order (the algorithm will return assemblies\n",
      "    composed of maximum `max_spikes` elements).\n",
      "    Default: `np.inf`\n",
      "significance_pruning : bool, optional\n",
      "    If True, the method performs significance pruning among\n",
      "    the detected assemblies.\n",
      "    Default: True\n",
      "subgroup_pruning : bool, optional\n",
      "    If True, the method performs subgroup pruning among\n",
      "    the detected assemblies.\n",
      "    Default: True\n",
      "same_configuration_pruning : bool, optional\n",
      "    If True, performs pruning (not present in the original code and more\n",
      "    efficient), not testing assemblies already formed\n",
      "    if they appear in the very same configuration.\n",
      "    Default: False\n",
      "bool_times_format : bool, optional\n",
      "    .. deprecated:: 0.10.0\n",
      "    Has no effect, the returning 'times' are always a quantity array\n",
      "    specifying the pattern spike times.\n",
      "    Default: None\n",
      "verbose : bool, optional\n",
      "    Regulates the number of prints given by the method. If true all prints\n",
      "    are given, otherwise the method does give any prints.\n",
      "    Default: False\n",
      "\n",
      "Returns\n",
      "-------\n",
      "assembly : list of dict\n",
      "    Contains the assemblies detected for the bin size chosen. Each\n",
      "    assembly is a dictionary with attributes:\n",
      "\n",
      "    'neurons' : list\n",
      "        Vector of units taking part to the assembly (unit order correspond\n",
      "        to the agglomeration order).\n",
      "    'lag' : pq.Quantity\n",
      "        Vector of time lags.\n",
      "        `lag[z]` is the activation delay between `neurons[1]` and\n",
      "        `neurons[z+1]`.\n",
      "    'pvalue' : list\n",
      "        Vector containing p-values.\n",
      "        `pvalue[z]` is the p-value of the statistical test between\n",
      "        performed adding `neurons[z+1]` to the `neurons[1:z]`.\n",
      "    'times' : pq.Quantity\n",
      "        Assembly activation times in the units of `binned_spiketrain`.\n",
      "    'signature' : np.ndarray\n",
      "        Array of two entries `(z,c)`. The first is the number of neurons\n",
      "        participating in the assembly (size), and the second is number of\n",
      "        assembly occurrences.\n",
      "\n",
      "Raises\n",
      "------\n",
      "TypeError\n",
      "    If `binned_spiketrain` is not an instance of\n",
      "    `elephant.conversion.BinnedSpikeTrain`.\n",
      "ValueError\n",
      "    If the parameters are out of bounds.\n",
      "\n",
      "Notes\n",
      "-----\n",
      "Alias: cad\n",
      "\u001b[0;31mFile:\u001b[0m      ~/opt/anaconda3/envs/brainhack/lib/python3.9/site-packages/elephant/cell_assembly_detection.py\n",
      "\u001b[0;31mType:\u001b[0m      function\n"
     ]
    }
   ],
   "source": [
    "from elephant.cell_assembly_detection import cell_assembly_detection\n",
    "cell_assembly_detection?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf629ff",
   "metadata": {},
   "source": [
    "All in one function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79922ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_and_test(A_sync=A_sync, shift=shift, winlen=1, slope=0., t_stop=10*pq.s):\n",
    "\n",
    "    A = [0]+[1.-A_sync]+[0]*8+[A_sync]\n",
    "    spiketrains = elephant.spike_train_generation.compound_poisson_process(\n",
    "                             rate=5*pq.Hz, A=A, shift=shift*pq.s, t_stop=t_stop)\n",
    "    for i_st in range(10):\n",
    "        delay = (i_st*slope)*pq.s\n",
    "        spike_times = np.sort(np.mod(spiketrains[i_st].times + delay, t_stop))\n",
    "        spiketrains[i_st] = neo.SpikeTrain(spike_times, t_start=0*pq.s, t_stop=t_stop)\n",
    "\n",
    "    for i in range(90):\n",
    "        spiketrains.append(elephant.spike_train_generation.homogeneous_poisson_process(\n",
    "            rate=5*pq.Hz, t_stop=10*pq.s))\n",
    "\n",
    "    bst = BinnedSpikeTrain(spiketrains, bin_size=1 * pq.ms)   \n",
    "    bst.rescale('ms')                          \n",
    "\n",
    "    patterns = cell_assembly_detection(bst, max_lag=10)\n",
    "\n",
    "    return patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5488bfdb",
   "metadata": {},
   "source": [
    "\n",
    "* changing the synchrony probability to check when SPADE will begin to fail:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8bc9a171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 []\n"
     ]
    }
   ],
   "source": [
    "for slope_ in np.logspace(-1, 1, 10, base=10):\n",
    "    patterns = generate_and_test(slope=slope_)\n",
    "    print(slope_, patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59048cd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('brainhack')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "f76abcfae7407d101ef34ba86f468988314045e4e2c214982f718a8acd3606b2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
